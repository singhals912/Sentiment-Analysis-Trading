{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9403ca36",
    "outputId": "11bafa20-02de-4829-81b6-ed8fe8256ecd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sachinsinghal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sachinsinghal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.datasets import imdb \n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "# import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e71373a6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dropout, Dense, Input, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Virgin America dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Users/sachinsinghal/Downloads/Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                        0.0  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold      name negativereason_gold  retweet_count  \\\n",
       "0                    NaN   cairdin                 NaN              0   \n",
       "1                    NaN  jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[['text','airline_sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the scrapped Tesla Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "0a5f5ac7"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/sachinsinghal/Downloads/StockTwits_Tesla_Mar-Jun.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "i9h-hBhFiJmi",
    "outputId": "394000a2-f18a-48b7-8493-60e5db7fc8d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>body</th>\n",
       "      <th>senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>299408922</td>\n",
       "      <td>2021-03-04 22:44:46+00:00</td>\n",
       "      <td>$TSLA I’m going to cry a little bit if this to...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>299409064</td>\n",
       "      <td>2021-03-04 22:45:06+00:00</td>\n",
       "      <td>$TSLA not short or involved. Definitely clear....</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id                 created_at  \\\n",
       "0           0  299408922  2021-03-04 22:44:46+00:00   \n",
       "1           1  299409064  2021-03-04 22:45:06+00:00   \n",
       "\n",
       "                                                body senti  \n",
       "0  $TSLA I’m going to cry a little bit if this to...        \n",
       "1  $TSLA not short or involved. Definitely clear....        "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "O9rUu01oiP5U"
   },
   "outputs": [],
   "source": [
    "df=df[['body','senti','created_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ftSGlPFWiZB1"
   },
   "outputs": [],
   "source": [
    "df1.rename({'airline_sentiment':'senti','text':'body'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing of Virgin America data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0de79aaf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# test = df[df['senti']==\" \"]\n",
    "data = df1[df1['senti']!=\" \"]\n",
    "\n",
    "#Lengh of the text\n",
    "data['length']=data['body'].apply(lambda x: len(x.split()))\n",
    "\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "data['body']= data['body'].apply(lambda x : remove_tags(x))\n",
    "\n",
    "def remove_tags(string):\n",
    "    result = re.sub(r'[^\\w\\s]', ' ', string)\n",
    "    return result\n",
    "data['body']= data['body'].apply(lambda x : remove_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>senti</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VirginAmerica What  dhepburn said</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VirginAmerica plus you ve added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body     senti  length\n",
       "0                 VirginAmerica What  dhepburn said    neutral       4\n",
       "1   VirginAmerica plus you ve added commercials t...  positive       9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out tweets less than length of 3 and replacing Virgin America with blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "675a12fe",
    "outputId": "44b96aa2-a331-43ae-de6c-7eaa852bc07e"
   },
   "outputs": [],
   "source": [
    "data_1 = data[data['length']>3]\n",
    "\n",
    "data_1['body'] = data_1['body'].apply(lambda x:x.replace('VirginAmerica',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking tweets posted between 9am to 4pm for scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "bb8596a0"
   },
   "outputs": [],
   "source": [
    "df['created_at'] = df['created_at'].apply(lambda x:datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S+00:00'))\n",
    "df['Hour'] = df['created_at'].apply(lambda x:x.hour)\n",
    "df['Month'] = df['created_at'].apply(lambda x:x.month)\n",
    "df['weekday'] = df['created_at'].apply(lambda x: x.weekday())\n",
    "df['day'] = df['created_at'].apply(lambda x: x.day)\n",
    "\n",
    "df_current = df[(df['weekday'] < 5) & (df['Hour'] > 8)  & (df['Hour'] < 16)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing of scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cbb061d",
    "outputId": "f7ddda1b-f0ca-4608-d4d6-1c3863d9dfaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsinghal/miniforge3/envs/tf_m1/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "<ipython-input-120-04bc749a8be7>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_current['length']=df_current['body'].apply(lambda x: len(x.split()))\n",
      "<ipython-input-120-04bc749a8be7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_current['body']= df_current['body'].apply(lambda cw : remove_tags(cw))\n",
      "<ipython-input-120-04bc749a8be7>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_current['body']= df_current['body'].apply(lambda cw : remove_tags(cw))\n"
     ]
    }
   ],
   "source": [
    "df_current.drop(['senti','Hour','Month','weekday'],axis=1, inplace=True)\n",
    "\n",
    "df_current['length']=df_current['body'].apply(lambda x: len(x.split()))\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "df_current['body']= df_current['body'].apply(lambda cw : remove_tags(cw))\n",
    "def remove_tags(string):\n",
    "    result = re.sub(r'[^\\w\\s]', ' ', string)\n",
    "    return result\n",
    "df_current['body']= df_current['body'].apply(lambda cw : remove_tags(cw))\n",
    "df_current = df_current[df_current['length']>3]\n",
    "df_current['body'] = df_current['body'].apply(lambda x:x.replace('BTC.X',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "x5_28Nk3itBH",
    "outputId": "ee7b156b-0302-49c2-a6ef-5cc01915713b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>senti</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus you ve added commercials to the experie...</td>\n",
       "      <td>positive</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it s really aggressive to blast obnoxious  e...</td>\n",
       "      <td>negative</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body     senti  length\n",
       "1    plus you ve added commercials to the experie...  positive       9\n",
       "3    it s really aggressive to blast obnoxious  e...  negative      17"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing tweets with neutral sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ks-NC5nmi1Gm"
   },
   "outputs": [],
   "source": [
    "data_1 = data_1[data_1['senti']!='neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and splitting the VA dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "eb18ff30"
   },
   "outputs": [],
   "source": [
    "data_1['body'] = data_1['body'].str.lower()\n",
    "\n",
    "reviews_tokenized = data_1['body'].apply(nltk.word_tokenize).tolist()\n",
    "reviews_list=[]\n",
    "for row in reviews_tokenized:\n",
    "    reviews_list.append([token.lower() for token in row if token.isalpha() if len(token)>1])\n",
    "\n",
    "X_train, X_test,Y_train, Y_test = train_test_split(reviews_list, data_1['senti'], test_size=0.2, random_state = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9132\n",
       "positive    2209\n",
       "Name: senti, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1['senti'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting positive and negative to numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "918fea0e"
   },
   "outputs": [],
   "source": [
    "Y_train = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, Y_train)))\n",
    "Y_test = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "703b7f7c"
   },
   "outputs": [],
   "source": [
    "#Create dictionary to store 5000 most frequent words \n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "b082e7af"
   },
   "outputs": [],
   "source": [
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxLen = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0600caae",
    "outputId": "9e4770de-8da5-478d-e361-16a9a9337bba"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 64))\n",
    "# model.add(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2,return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(layers.LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid', kernel_regularizer='l2'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c865945",
    "outputId": "8f21d9e5-c478-490e-f5e2-986ea02e3c5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9072, 50)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get index of the tweets from the dictionary \n",
    "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "#Pad to get the length=max_length \n",
    "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')\n",
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu_XF4yrh1cb",
    "outputId": "00eca316-f646-4ded-e73d-1a96944bc627"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9072,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ff49729",
    "outputId": "ee762df5-288c-4583-a4b0-72be6bac8a6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "57/57 [==============================] - 8s 133ms/step - loss: 0.5609 - accuracy: 0.7691 - val_loss: 0.5146 - val_accuracy: 0.8149\n",
      "Epoch 2/32\n",
      "57/57 [==============================] - 8s 138ms/step - loss: 0.5137 - accuracy: 0.8086 - val_loss: 0.4869 - val_accuracy: 0.8149\n",
      "Epoch 3/32\n",
      "57/57 [==============================] - 8s 139ms/step - loss: 0.4301 - accuracy: 0.8227 - val_loss: 0.3086 - val_accuracy: 0.9052\n",
      "Epoch 4/32\n",
      "57/57 [==============================] - 9s 161ms/step - loss: 0.2809 - accuracy: 0.9052 - val_loss: 0.2548 - val_accuracy: 0.9201\n",
      "Epoch 5/32\n",
      "57/57 [==============================] - 9s 160ms/step - loss: 0.2251 - accuracy: 0.9312 - val_loss: 0.2430 - val_accuracy: 0.9201\n",
      "Epoch 6/32\n",
      "57/57 [==============================] - 9s 161ms/step - loss: 0.2033 - accuracy: 0.9470 - val_loss: 0.2601 - val_accuracy: 0.9140\n",
      "Epoch 7/32\n",
      "57/57 [==============================] - 9s 165ms/step - loss: 0.1589 - accuracy: 0.9599 - val_loss: 0.2659 - val_accuracy: 0.9168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29851e0a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 128\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train_indices, Y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbecbaac",
    "outputId": "e2079a58-33fd-493c-c70d-9da9276623d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2269, 50)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
    "X_test_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20750fc9",
    "outputId": "d0a05d29-deb3-4fe0-d7ad-f3162230c0af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 91.19%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test_indices, Y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrQ2lkPi_IFR",
    "outputId": "5cc56ba5-74ac-4fed-dfc4-13c83761b147"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0075321 ],\n",
       "       [0.03656246],\n",
       "       [0.9311236 ],\n",
       "       ...,\n",
       "       [0.01068546],\n",
       "       [0.01112958],\n",
       "       [0.9457163 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the stocktwits scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "dc00574c"
   },
   "outputs": [],
   "source": [
    "df_current['body'] = df_current['body'].str.lower()\n",
    "\n",
    "reviews_tokenized = df_current['body'].apply(nltk.word_tokenize).tolist()\n",
    "current_data=[]\n",
    "for row in reviews_tokenized:\n",
    "    current_data.append([token.lower() for token in row if token.isalpha() if len(token)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqhJ0PLBKapP",
    "outputId": "9488ec2d-488b-405a-f8ff-5f7778d86f7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69007, 50)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_indices = tokenizer.texts_to_sequences(current_data)\n",
    "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
    "X_test_indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the trained model to predict the sentiment score on scrapped tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "u0ID5OyXKZx1"
   },
   "outputs": [],
   "source": [
    "def add_score_predictions(df_new, X_test_indices):\n",
    "\n",
    "    df_new['sentiment score'] = 0\n",
    "\n",
    "    #     reviews_list_idx = pad_sequences(reviews_list_idx, maxlen=maxLen, padding='post')\n",
    "\n",
    "    review_preds = model.predict(X_test_indices)\n",
    "\n",
    "    df_new['sentiment score'] = review_preds\n",
    "\n",
    "    pred_sentiment = np.array(list(map(lambda x : '1' if x > 0.5 else '0',review_preds)))\n",
    "\n",
    "    df_new['predicted sentiment'] = 0\n",
    "\n",
    "    df_new['predicted sentiment'] = pred_sentiment\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "BEZSOITnKbna"
   },
   "outputs": [],
   "source": [
    "data = add_score_predictions(df_current, X_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['predicted sentiment'] = data['predicted sentiment'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "3SVfMvBGKb2e",
    "outputId": "95d2dd5d-05f7-45b4-ee44-e77da0b6173c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['date'] = data['created_at'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37892327"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the histogram of the sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([32431.,  3720.,  2348.,  1691.,  1556.,  1572.,  1772.,  2202.,\n",
       "         4266., 17449.]),\n",
       " array([0.00621895, 0.10130312, 0.19638728, 0.29147145, 0.3865556 ,\n",
       "        0.48163977, 0.57672393, 0.67180806, 0.76689225, 0.8619764 ,\n",
       "        0.9570606 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['sentiment score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating the data daywise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated=data.groupby(['date']).aggregate({'predicted sentiment':np.sum,'day':np.size,'sentiment score':np.average}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>+ve Tweets</th>\n",
       "      <th>Total Tweets</th>\n",
       "      <th>Average Sentiment</th>\n",
       "      <th>+ve Tweets ratio</th>\n",
       "      <th>Predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>369</td>\n",
       "      <td>966</td>\n",
       "      <td>0.373269</td>\n",
       "      <td>0.381988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>325</td>\n",
       "      <td>803</td>\n",
       "      <td>0.385182</td>\n",
       "      <td>0.404732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>377</td>\n",
       "      <td>856</td>\n",
       "      <td>0.416378</td>\n",
       "      <td>0.440421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>389</td>\n",
       "      <td>948</td>\n",
       "      <td>0.400061</td>\n",
       "      <td>0.410338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>370</td>\n",
       "      <td>873</td>\n",
       "      <td>0.402046</td>\n",
       "      <td>0.423826</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2021-06-21</td>\n",
       "      <td>253</td>\n",
       "      <td>678</td>\n",
       "      <td>0.369783</td>\n",
       "      <td>0.373156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>255</td>\n",
       "      <td>659</td>\n",
       "      <td>0.376671</td>\n",
       "      <td>0.386950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2021-06-23</td>\n",
       "      <td>375</td>\n",
       "      <td>875</td>\n",
       "      <td>0.413874</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>389</td>\n",
       "      <td>905</td>\n",
       "      <td>0.418163</td>\n",
       "      <td>0.429834</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>367</td>\n",
       "      <td>921</td>\n",
       "      <td>0.391728</td>\n",
       "      <td>0.398480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  +ve Tweets  Total Tweets  Average Sentiment  +ve Tweets ratio  \\\n",
       "0   2021-03-05         369           966           0.373269          0.381988   \n",
       "1   2021-03-08         325           803           0.385182          0.404732   \n",
       "2   2021-03-09         377           856           0.416378          0.440421   \n",
       "3   2021-03-10         389           948           0.400061          0.410338   \n",
       "4   2021-03-11         370           873           0.402046          0.423826   \n",
       "..         ...         ...           ...                ...               ...   \n",
       "76  2021-06-21         253           678           0.369783          0.373156   \n",
       "77  2021-06-22         255           659           0.376671          0.386950   \n",
       "78  2021-06-23         375           875           0.413874          0.428571   \n",
       "79  2021-06-24         389           905           0.418163          0.429834   \n",
       "80  2021-06-25         367           921           0.391728          0.398480   \n",
       "\n",
       "    Predicted_sentiment  \n",
       "0                     0  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  \n",
       "..                  ...  \n",
       "76                    0  \n",
       "77                    0  \n",
       "78                    1  \n",
       "79                    1  \n",
       "80                    1  \n",
       "\n",
       "[81 rows x 6 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated.rename({'predicted sentiment':'+ve Tweets','day':'Total Tweets','sentiment score':'Average Sentiment'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated['+ve Tweets ratio']=aggregated['+ve Tweets']/aggregated['Total Tweets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Prediction on the scrapped data using the sentiment score mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated['Predicted_sentiment']=aggregated['Average Sentiment'].apply(lambda x: 1 if x>data['sentiment score'].mean() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the ticker data from Yahoo finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IReidYV5KcFr",
    "outputId": "69252dac-eb76-44b3-d70c-4a5293ecd92a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-05</th>\n",
       "      <td>626.059998</td>\n",
       "      <td>627.840027</td>\n",
       "      <td>539.489990</td>\n",
       "      <td>597.950012</td>\n",
       "      <td>89396500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-08</th>\n",
       "      <td>600.549988</td>\n",
       "      <td>620.130005</td>\n",
       "      <td>558.789978</td>\n",
       "      <td>563.000000</td>\n",
       "      <td>51787000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>608.179993</td>\n",
       "      <td>678.090027</td>\n",
       "      <td>595.210022</td>\n",
       "      <td>673.580017</td>\n",
       "      <td>67523300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10</th>\n",
       "      <td>700.299988</td>\n",
       "      <td>717.849976</td>\n",
       "      <td>655.059998</td>\n",
       "      <td>668.059998</td>\n",
       "      <td>60605700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11</th>\n",
       "      <td>699.400024</td>\n",
       "      <td>702.500000</td>\n",
       "      <td>677.179993</td>\n",
       "      <td>699.599976</td>\n",
       "      <td>36253900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23</th>\n",
       "      <td>632.000000</td>\n",
       "      <td>657.200012</td>\n",
       "      <td>630.039978</td>\n",
       "      <td>656.570007</td>\n",
       "      <td>31099200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-24</th>\n",
       "      <td>674.989990</td>\n",
       "      <td>697.619995</td>\n",
       "      <td>667.609985</td>\n",
       "      <td>679.820007</td>\n",
       "      <td>45982400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-25</th>\n",
       "      <td>689.580017</td>\n",
       "      <td>693.809998</td>\n",
       "      <td>668.700012</td>\n",
       "      <td>671.869995</td>\n",
       "      <td>32496700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28</th>\n",
       "      <td>671.640015</td>\n",
       "      <td>694.700012</td>\n",
       "      <td>670.320007</td>\n",
       "      <td>688.719971</td>\n",
       "      <td>21628200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29</th>\n",
       "      <td>684.650024</td>\n",
       "      <td>687.510010</td>\n",
       "      <td>675.890015</td>\n",
       "      <td>680.760010</td>\n",
       "      <td>17381300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close    Volume  \\\n",
       "Date                                                                   \n",
       "2021-03-05  626.059998  627.840027  539.489990  597.950012  89396500   \n",
       "2021-03-08  600.549988  620.130005  558.789978  563.000000  51787000   \n",
       "2021-03-09  608.179993  678.090027  595.210022  673.580017  67523300   \n",
       "2021-03-10  700.299988  717.849976  655.059998  668.059998  60605700   \n",
       "2021-03-11  699.400024  702.500000  677.179993  699.599976  36253900   \n",
       "...                ...         ...         ...         ...       ...   \n",
       "2021-06-23  632.000000  657.200012  630.039978  656.570007  31099200   \n",
       "2021-06-24  674.989990  697.619995  667.609985  679.820007  45982400   \n",
       "2021-06-25  689.580017  693.809998  668.700012  671.869995  32496700   \n",
       "2021-06-28  671.640015  694.700012  670.320007  688.719971  21628200   \n",
       "2021-06-29  684.650024  687.510010  675.890015  680.760010  17381300   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "2021-03-05          0             0  \n",
       "2021-03-08          0             0  \n",
       "2021-03-09          0             0  \n",
       "2021-03-10          0             0  \n",
       "2021-03-11          0             0  \n",
       "...               ...           ...  \n",
       "2021-06-23          0             0  \n",
       "2021-06-24          0             0  \n",
       "2021-06-25          0             0  \n",
       "2021-06-28          0             0  \n",
       "2021-06-29          0             0  \n",
       "\n",
       "[81 rows x 7 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "#define the ticker symbol\n",
    "tickerSymbol = 'TSLA'\n",
    "\n",
    "#get data on this ticker\n",
    "tickerData = yf.Ticker(tickerSymbol)\n",
    "\n",
    "#get the historical prices for this ticker\n",
    "tickerDf = tickerData.history(period='1d', start='2021-3-5', end='2021-6-30')\n",
    "\n",
    "#see your data\n",
    "tickerDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "7JQER7JPnwRp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open            float64\n",
       "High            float64\n",
       "Low             float64\n",
       "Close           float64\n",
       "Volume            int64\n",
       "Dividends         int64\n",
       "Stock Splits      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickerDf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_1 = aggregated.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the TSLA ticker data with our aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_2 = aggregated_1.join(tickerDf,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_2.drop(['High','Low','Volume','Dividends','Stock Splits'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+ve Tweets</th>\n",
       "      <th>Total Tweets</th>\n",
       "      <th>Average Sentiment</th>\n",
       "      <th>+ve Tweets ratio</th>\n",
       "      <th>Predicted_sentiment</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Actual_Market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-05</th>\n",
       "      <td>369.0</td>\n",
       "      <td>966.0</td>\n",
       "      <td>0.373269</td>\n",
       "      <td>0.381988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>626.059998</td>\n",
       "      <td>597.950012</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-08</th>\n",
       "      <td>325.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>0.385182</td>\n",
       "      <td>0.404732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600.549988</td>\n",
       "      <td>563.000000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>377.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>0.416378</td>\n",
       "      <td>0.440421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>608.179993</td>\n",
       "      <td>673.580017</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10</th>\n",
       "      <td>389.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.400061</td>\n",
       "      <td>0.410338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>700.299988</td>\n",
       "      <td>668.059998</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11</th>\n",
       "      <td>370.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>0.402046</td>\n",
       "      <td>0.423826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>699.400024</td>\n",
       "      <td>699.599976</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-21</th>\n",
       "      <td>253.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>0.369783</td>\n",
       "      <td>0.373156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>624.479980</td>\n",
       "      <td>620.830017</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-22</th>\n",
       "      <td>255.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>0.376671</td>\n",
       "      <td>0.386950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618.250000</td>\n",
       "      <td>623.710022</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23</th>\n",
       "      <td>375.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>0.413874</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>632.000000</td>\n",
       "      <td>656.570007</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-24</th>\n",
       "      <td>389.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>0.418163</td>\n",
       "      <td>0.429834</td>\n",
       "      <td>1.0</td>\n",
       "      <td>674.989990</td>\n",
       "      <td>679.820007</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-25</th>\n",
       "      <td>367.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>0.391728</td>\n",
       "      <td>0.398480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>689.580017</td>\n",
       "      <td>671.869995</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            +ve Tweets  Total Tweets  Average Sentiment  +ve Tweets ratio  \\\n",
       "2021-03-05       369.0         966.0           0.373269          0.381988   \n",
       "2021-03-08       325.0         803.0           0.385182          0.404732   \n",
       "2021-03-09       377.0         856.0           0.416378          0.440421   \n",
       "2021-03-10       389.0         948.0           0.400061          0.410338   \n",
       "2021-03-11       370.0         873.0           0.402046          0.423826   \n",
       "...                ...           ...                ...               ...   \n",
       "2021-06-21       253.0         678.0           0.369783          0.373156   \n",
       "2021-06-22       255.0         659.0           0.376671          0.386950   \n",
       "2021-06-23       375.0         875.0           0.413874          0.428571   \n",
       "2021-06-24       389.0         905.0           0.418163          0.429834   \n",
       "2021-06-25       367.0         921.0           0.391728          0.398480   \n",
       "\n",
       "            Predicted_sentiment        Open       Close Actual_Market  \n",
       "2021-03-05                  0.0  626.059998  597.950012      Negative  \n",
       "2021-03-08                  1.0  600.549988  563.000000      Negative  \n",
       "2021-03-09                  1.0  608.179993  673.580017      Positive  \n",
       "2021-03-10                  1.0  700.299988  668.059998      Negative  \n",
       "2021-03-11                  1.0  699.400024  699.599976      Positive  \n",
       "...                         ...         ...         ...           ...  \n",
       "2021-06-21                  0.0  624.479980  620.830017      Negative  \n",
       "2021-06-22                  0.0  618.250000  623.710022      Positive  \n",
       "2021-06-23                  1.0  632.000000  656.570007      Positive  \n",
       "2021-06-24                  1.0  674.989990  679.820007      Positive  \n",
       "2021-06-25                  1.0  689.580017  671.869995      Negative  \n",
       "\n",
       "[79 rows x 8 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x['Close'] > x['Open']:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "        \n",
    "aggregated_2['Actual_Market']=aggregated_2.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_3 = aggregated_2[['Predicted_sentiment','Actual_Market']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sachinsinghal/miniforge3/envs/tf_m1/lib/python3.8/site-packages/pandas/core/series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "aggregated_3['Actual_Market'].replace({'Negative':0,'Positive':1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-220-5f801247c23a>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  aggregated_3['Match']=aggregated_3.apply(f, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x['Predicted_sentiment'] == x['Actual_Market']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "aggregated_3['Match']=aggregated_3.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of our predicted sentiment with that of our yahoo finance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.43037974683544"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (aggregated_3['Match'].sum()/aggregated_3['Match'].count())*100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_sentiment</th>\n",
       "      <th>Actual_Market</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-08</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted_sentiment  Actual_Market  Match\n",
       "2021-03-05                  0.0              0   True\n",
       "2021-03-08                  1.0              0  False\n",
       "2021-03-09                  1.0              1   True\n",
       "2021-03-10                  1.0              0  False\n",
       "2021-03-11                  1.0              1   True\n",
       "...                         ...            ...    ...\n",
       "2021-06-21                  0.0              0   True\n",
       "2021-06-22                  0.0              1  False\n",
       "2021-06-23                  1.0              1   True\n",
       "2021-06-24                  1.0              1   True\n",
       "2021-06-25                  1.0              0  False\n",
       "\n",
       "[79 rows x 3 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 321,601\n",
      "Trainable params: 321,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.SimpleRNN(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "114/114 [==============================] - 3s 16ms/step - loss: 0.6168 - accuracy: 0.6651 - val_loss: 0.4832 - val_accuracy: 0.8149\n",
      "Epoch 2/32\n",
      "114/114 [==============================] - 2s 15ms/step - loss: 0.5130 - accuracy: 0.7987 - val_loss: 0.4791 - val_accuracy: 0.8149\n",
      "Epoch 3/32\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.5008 - accuracy: 0.8037 - val_loss: 0.4753 - val_accuracy: 0.8149\n",
      "Epoch 4/32\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.4970 - accuracy: 0.7977 - val_loss: 0.4552 - val_accuracy: 0.8149\n",
      "Epoch 5/32\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.4956 - accuracy: 0.7949 - val_loss: 0.4490 - val_accuracy: 0.8149\n",
      "Epoch 6/32\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.4706 - accuracy: 0.8049 - val_loss: 0.4567 - val_accuracy: 0.8149\n",
      "Epoch 7/32\n",
      "114/114 [==============================] - 2s 14ms/step - loss: 0.4831 - accuracy: 0.8023 - val_loss: 0.4550 - val_accuracy: 0.8149\n",
      "Testing set accuracy: 80.48%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train_indices, Y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])\n",
    "\n",
    "_, acc = model.evaluate(X_test_indices, Y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN using the entire sequence instead of the last output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 50, 16)            320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 50, 32)            1568      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1601      \n",
      "=================================================================\n",
      "Total params: 323,169\n",
      "Trainable params: 323,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16, input_length=maxLen))\n",
    "model.add(layers.SimpleRNN(32, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "114/114 [==============================] - 2s 14ms/step - loss: 0.5398 - accuracy: 0.7590 - val_loss: 0.3310 - val_accuracy: 0.8628\n",
      "Epoch 2/32\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.3797 - accuracy: 0.8514 - val_loss: 0.2708 - val_accuracy: 0.8843\n",
      "Epoch 3/32\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.2896 - accuracy: 0.8828 - val_loss: 0.2288 - val_accuracy: 0.8992\n",
      "Epoch 4/32\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.2302 - accuracy: 0.9142 - val_loss: 0.2108 - val_accuracy: 0.9124\n",
      "Epoch 5/32\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.1845 - accuracy: 0.9336 - val_loss: 0.1969 - val_accuracy: 0.9179\n",
      "Epoch 6/32\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.1506 - accuracy: 0.9426 - val_loss: 0.1935 - val_accuracy: 0.9190\n",
      "Epoch 7/32\n",
      "114/114 [==============================] - 2s 14ms/step - loss: 0.1372 - accuracy: 0.9520 - val_loss: 0.1987 - val_accuracy: 0.9229\n",
      "Epoch 8/32\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.1234 - accuracy: 0.9557 - val_loss: 0.2029 - val_accuracy: 0.9251\n",
      "Testing set accuracy: 90.97%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train_indices, Y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])\n",
    "\n",
    "_, acc = model.evaluate(X_test_indices, Y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 128)         74240     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 525,953\n",
      "Trainable params: 525,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "114/114 [==============================] - 34s 271ms/step - loss: 0.5234 - accuracy: 0.7908 - val_loss: 0.4813 - val_accuracy: 0.8149\n",
      "Epoch 2/32\n",
      "114/114 [==============================] - 61s 535ms/step - loss: 0.5069 - accuracy: 0.7974 - val_loss: 0.4788 - val_accuracy: 0.8149\n",
      "Epoch 3/32\n",
      "114/114 [==============================] - 71s 622ms/step - loss: 0.4537 - accuracy: 0.8119 - val_loss: 0.2950 - val_accuracy: 0.8882\n",
      "Epoch 4/32\n",
      "114/114 [==============================] - 64s 557ms/step - loss: 0.3194 - accuracy: 0.8827 - val_loss: 0.2295 - val_accuracy: 0.9019\n",
      "Epoch 5/32\n",
      "114/114 [==============================] - 62s 544ms/step - loss: 0.2610 - accuracy: 0.8946 - val_loss: 0.2282 - val_accuracy: 0.9124\n",
      "Epoch 6/32\n",
      "114/114 [==============================] - 66s 575ms/step - loss: 0.2199 - accuracy: 0.9271 - val_loss: 0.2261 - val_accuracy: 0.9063\n",
      "Epoch 7/32\n",
      "114/114 [==============================] - 90s 789ms/step - loss: 0.1865 - accuracy: 0.9308 - val_loss: 0.2228 - val_accuracy: 0.9212\n",
      "Epoch 8/32\n",
      "114/114 [==============================] - 79s 696ms/step - loss: 0.1514 - accuracy: 0.9521 - val_loss: 0.2207 - val_accuracy: 0.9251\n",
      "Epoch 9/32\n",
      "114/114 [==============================] - 75s 660ms/step - loss: 0.1527 - accuracy: 0.9518 - val_loss: 0.2482 - val_accuracy: 0.9245\n",
      "Epoch 10/32\n",
      "114/114 [==============================] - 79s 695ms/step - loss: 0.1306 - accuracy: 0.9573 - val_loss: 0.2256 - val_accuracy: 0.9267\n",
      "Testing set accuracy: 91.54%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train_indices, Y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])\n",
    "\n",
    "_, acc = model.evaluate(X_test_indices, Y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               148480    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 468,737\n",
      "Trainable params: 468,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "114/114 [==============================] - 34s 282ms/step - loss: 0.5129 - accuracy: 0.7711 - val_loss: 0.3416 - val_accuracy: 0.8562\n",
      "Epoch 2/32\n",
      "114/114 [==============================] - 33s 289ms/step - loss: 0.3107 - accuracy: 0.8687 - val_loss: 0.2295 - val_accuracy: 0.9019\n",
      "Epoch 3/32\n",
      "114/114 [==============================] - 51s 445ms/step - loss: 0.2122 - accuracy: 0.9186 - val_loss: 0.2004 - val_accuracy: 0.9190\n",
      "Epoch 4/32\n",
      "114/114 [==============================] - 55s 478ms/step - loss: 0.1856 - accuracy: 0.9339 - val_loss: 0.1905 - val_accuracy: 0.9240\n",
      "Epoch 5/32\n",
      "114/114 [==============================] - 55s 481ms/step - loss: 0.1479 - accuracy: 0.9445 - val_loss: 0.1904 - val_accuracy: 0.9229\n",
      "Epoch 6/32\n",
      "114/114 [==============================] - 62s 544ms/step - loss: 0.1395 - accuracy: 0.9488 - val_loss: 0.1911 - val_accuracy: 0.9207\n",
      "Epoch 7/32\n",
      "114/114 [==============================] - 74s 648ms/step - loss: 0.1207 - accuracy: 0.9550 - val_loss: 0.2067 - val_accuracy: 0.9223\n",
      "Testing set accuracy: 91.89%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train_indices, Y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])\n",
    "\n",
    "_, acc = model.evaluate(X_test_indices, Y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_updated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
